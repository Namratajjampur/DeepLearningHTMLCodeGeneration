{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNgiQX5u7S7muALU/eplS0H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namratajjampur/DeepLearningHTMLCodeGeneration/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DBifmf5EwnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "67989f19-f004-4e31-bbc7-67e23e45ddff"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "if tf.test.gpu_device_name():     \n",
        "  print('Default GPU Device: {}'.format(tf.test.gpu_device_name())) \n",
        "else:     \n",
        "  print(\"Please install GPU version of TF\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "Default GPU Device: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgMwdK8EE2MZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "adf769ed-179b-4d8e-a1e4-4bcb5c6d9373"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# import tensorflow as tf\n",
        "#from tensorflow.examples.tutorials.mnist import input_data\n",
        "from keras.datasets import fashion_mnist\n",
        "%matplotlib inline\n",
        "import os\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#data = input_data.read_data_sets('data/fashion',one_hot=True)\n",
        "\n",
        "label_dict = {\n",
        " 0: 'T-shirt/top',\n",
        " 1: 'Trouser',\n",
        " 2: 'Pullover',\n",
        " 3: 'Dress',\n",
        " 4: 'Coat',\n",
        " 5: 'Sandal',\n",
        " 6: 'Shirt',\n",
        " 7: 'Sneaker',\n",
        " 8: 'Bag',\n",
        " 9: 'Ankle boot',\n",
        "}\n",
        "\n",
        "#train_X = data.train.images.reshape(-1, 56, 56, 1)\n",
        "#test_X = data.test.images.reshape(-1,56,56,1)\n",
        "\n",
        "#train_y = data.train.labels\n",
        "#test_y = data.test.labels\n",
        "\n",
        "# MNIST total classes (0-9 digits)\n",
        "n_classes = 10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "train_X = x_train.reshape(-1,28,28,1)\n",
        "test_X = x_test.reshape(-1,28,28,1)\n",
        "\n",
        "train_y = to_categorical(y_train, n_classes)\n",
        "test_y = to_categorical(y_test, n_classes)\n",
        "\n",
        "\n",
        "print(test_X.shape,test_y.shape,train_X.shape,train_y.shape)\n",
        "print(x_test.shape,y_test.shape,x_train.shape,y_train.shape)\n",
        "\n",
        "training_iters = 1\n",
        "learning_rate = 0.001 \n",
        "batch_size = 128\n",
        "\n",
        "# MNIST data input (img shape: 28*28)\n",
        "n_input = 28\n",
        "\n",
        "\n",
        "\n",
        "#both placeholders are of type float\n",
        "x = tf.placeholder(\"float\", [None,28,28,1])\n",
        "y = tf.placeholder(\"float\", [None, n_classes])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28, 1) (10000, 10) (60000, 28, 28, 1) (60000, 10)\n",
            "(10000, 28, 28) (10000,) (60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMPeSluhF-U_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(x, w):\n",
        "    return tf.nn.conv2d(x, w, strides=[1,1,1,1], padding='SAME')\n",
        "\n",
        "def maxpool2d(x):\n",
        "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uAngxM3GhYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a51c2ada-de3c-4e79-b2c9-0e8ec8e390a4"
      },
      "source": [
        "weights = {\n",
        "    'W_conv1': tf.get_variable('W0', shape=(3,3,1,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'W_conv2': tf.get_variable('W1', shape=(3,3,32,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'W_conv3': tf.get_variable('W2', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'W_conv4': tf.get_variable('W3', shape=(3,3,64,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'W_conv5': tf.get_variable('W4', shape=(3,3,64,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'W_conv6': tf.get_variable('W5', shape=(3,3,128,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'W_fc1': tf.get_variable('W6', shape=(4*4*128,1024), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'W_fc2': tf.get_variable('W7', shape=(1024,1024), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'out': tf.get_variable('W8', shape=(1024,n_classes), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    }\n",
        "biases = {\n",
        "    'bc1': tf.get_variable('B0', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bc2': tf.get_variable('B1', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bc3': tf.get_variable('B2', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bc4': tf.get_variable('B3', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bc5': tf.get_variable('B4', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bc6': tf.get_variable('B5', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'b_fc1': tf.get_variable('B6', shape=(1024), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'b_fc2': tf.get_variable('B7', shape=(1024), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'out': tf.get_variable('B8', shape=(10), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    }"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V75-3Oy6Gk4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn(x,weights,biases):\n",
        "    print(\"in cnn\")\n",
        "    '''\n",
        "    weights = {'W_conv1':tf.Variable(tf.random_normal([3,3,1,32])),#56\n",
        "               'W_conv2':tf.Variable(tf.random_normal([3,3,32,32])),#56\n",
        "               'W_conv3':tf.Variable(tf.random_normal([3,3,32,64])),#28\n",
        "               'W_conv4':tf.Variable(tf.random_normal([3,3,64,64])),#28\n",
        "               'W_conv5':tf.Variable(tf.random_normal([3,3,64,128])),#14\n",
        "               'W_conv6':tf.Variable(tf.random_normal([3,3,128,128])),#14\n",
        "               'W_fc1':tf.Variable(tf.random_normal([7*7*128,1024])),  # since 3 times maxpooling.. inputsize/2^3\n",
        "               'W_fc2':tf.Variable(tf.random_normal([1024,1024]))\n",
        "              }\n",
        "                  # depending on what that repeat vector does\n",
        "\n",
        "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
        "               'b_conv2':tf.Variable(tf.random_normal([32])),\n",
        "               'b_conv3':tf.Variable(tf.random_normal([64])),\n",
        "               'b_conv4':tf.Variable(tf.random_normal([64])),\n",
        "               'b_conv5':tf.Variable(tf.random_normal([128])),\n",
        "               'b_conv6':tf.Variable(tf.random_normal([128])),\n",
        "               'b_fc1':tf.Variable(tf.random_normal([1024])),\n",
        "               'b_fc2':tf.Variable(tf.random_normal([1024]))\n",
        "             }\n",
        "    '''\n",
        "    \n",
        "\n",
        "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "\n",
        "    conv1 = tf.nn.relu(conv2d(x, weights['W_conv1'])+  biases['bc1'])\n",
        "    conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['bc2'])\n",
        "    conv2 = maxpool2d(conv2)\n",
        "    conv2 = tf.nn.dropout(conv2, 0.25)\n",
        "    \n",
        "    conv3 = tf.nn.relu(conv2d(conv2, weights['W_conv3']) + biases['bc3'])\n",
        "    conv4 = tf.nn.relu(conv2d(conv3, weights['W_conv4']) + biases['bc4'])\n",
        "    #conv4 = conv3\n",
        "    conv4 = maxpool2d(conv4)\n",
        "    conv4 = tf.nn.dropout(conv4, 0.25)\n",
        "    \n",
        "    conv5 = tf.nn.relu(conv2d(conv4, weights['W_conv5']) + biases['bc5'])\n",
        "    conv6 = tf.nn.relu(conv2d(conv5, weights['W_conv6']) + biases['bc6'])\n",
        "    #conv6 = conv5\n",
        "    conv6 = maxpool2d(conv6)\n",
        "    conv6 = tf.nn.dropout(conv6, 0.25)\n",
        "\n",
        "    fc1 = tf.reshape(conv6,[-1, weights['W_fc1'].get_shape().as_list()[0]])\n",
        "    fc1 = tf.nn.relu(tf.matmul(fc1, weights['W_fc1'])+biases['b_fc1'])\n",
        "    fc1 = tf.nn.dropout(fc1, 0.3)\n",
        "    \n",
        "    fc2 = tf.nn.relu(tf.matmul(fc1, weights['W_fc2'])+biases['b_fc2'])\n",
        "    fc2 = tf.nn.dropout(fc2, 0.3)  \n",
        "    #fc2 = fc1\n",
        "    \n",
        "    out = tf.add(tf.matmul(fc2, weights['out']), biases['out'])\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDpp_cuRGof6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "c4761837-6484-4501-9609-6fd0a3c65e5b"
      },
      "source": [
        "pred = cnn(x,weights,biases)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in cnn\n",
            "WARNING:tensorflow:From <ipython-input-5-500c80b01b10>:32: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:From <ipython-input-6-1976f3bce204>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezCmQQODGrkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
        "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "\n",
        "#calculate accuracy across all the given images and average them out. \n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cJrZBIfGvoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1HOxRC6Gzgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f0259b40-8233-4f0d-ab24-2cf592caf1b7"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init) \n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    train_accuracy = []\n",
        "    test_accuracy = []\n",
        "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
        "    for i in range(training_iters):\n",
        "        for batch in range(len(train_X)//batch_size):\n",
        "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
        "            batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
        "            # Run optimization op (backprop).\n",
        "                # Calculate batch loss and accuracy\n",
        "            opt = sess.run(optimizer, feed_dict={x: batch_x,\n",
        "                                                              y: batch_y})\n",
        "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
        "                                                              y: batch_y})\n",
        "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
        "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                      \"{:.5f}\".format(acc))\n",
        "        print(\"Optimization Finished!\")\n",
        "\n",
        "        # Calculate accuracy for all 10000 mnist test images\n",
        "    test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: test_X,y : test_y})\n",
        "    train_loss.append(loss)\n",
        "    test_loss.append(valid_loss)\n",
        "    train_accuracy.append(acc)\n",
        "    test_accuracy.append(test_acc)\n",
        "    print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
        "\n",
        "    \n",
        "    summary_writer.close()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter 0, Loss= 0.976348, Training Accuracy= 0.62500\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.62750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y5BhuMKG2O1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}