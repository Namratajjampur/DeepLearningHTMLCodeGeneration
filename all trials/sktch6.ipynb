{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.layers import Embedding\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, w):\n",
    "    return tf.nn.conv2d(x, w, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool2d(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_size=256\n",
    "vb_size=18\n",
    "batchsize=2\n",
    "weights = {\n",
    "    'W_conv1': tf.get_variable('W0', shape=(3,3,3,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'W_conv2': tf.get_variable('W1', shape=(3,3,32,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'W_conv3': tf.get_variable('W2', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'W_conv4': tf.get_variable('W3', shape=(3,3,64,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'W_conv5': tf.get_variable('W4', shape=(3,3,64,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'W_conv6': tf.get_variable('W5', shape=(3,3,128,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'W_fc1': tf.get_variable('W6', shape=(28*28*128,1024), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'W_fc2': tf.get_variable('W7', shape=(1024,50), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'out': tf.get_variable('W8', dtype = tf.float64,shape=(hidden_size,vb_size), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    }\n",
    "biases = {\n",
    "    'bc1': tf.get_variable('B0', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc2': tf.get_variable('B1', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc3': tf.get_variable('B2', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc4': tf.get_variable('B3', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc5': tf.get_variable('B4', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc6': tf.get_variable('B5', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'b_fc1': tf.get_variable('B6', shape=(1024), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'b_fc2': tf.get_variable('B7', shape=(50), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'out': tf.get_variable('B8', dtype = tf.float64,shape=(vb_size), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_cell(object):\n",
    "\n",
    "    def __init__(self, input_nodes, hidden_unit, output_nodes):\n",
    "\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_unit = hidden_unit\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        self.Wx = tf.Variable(tf.zeros([self.input_nodes, self.hidden_unit]))\n",
    "\n",
    "        self.Wr = tf.Variable(tf.zeros([self.input_nodes, self.hidden_unit]))\n",
    "        self.br = tf.Variable(tf.truncated_normal([self.hidden_unit], mean=1))\n",
    "        \n",
    "        self.Wz = tf.Variable(tf.zeros([self.input_nodes, self.hidden_unit]))\n",
    "        self.bz = tf.Variable(tf.truncated_normal([self.hidden_unit], mean=1))\n",
    "\n",
    "        self.Wh = tf.Variable(tf.zeros([self.hidden_unit, self.hidden_unit]))\n",
    "\n",
    "        self.Wo = tf.Variable(tf.truncated_normal([self.hidden_unit, self.output_nodes], mean=1, stddev=.01))\n",
    "        self.bo = tf.Variable(tf.truncated_normal([self.output_nodes], mean=1, stddev=.01))\n",
    "\n",
    "        self.images = tf.placeholder(tf.float32,shape=[None, self.input_nodes/2], name='images')\n",
    "        self.words = tf.placeholder(tf.int32,shape=[None, None], name='words')\n",
    "#         batch_input_ = tf.transpose(self._inputs, perm=[2, 0, 1])\n",
    "#         self.processed_input = tf.transpose(batch_input_)\n",
    "\n",
    "#         batch_input_ = tf.transpose(self._inputs, perm=[2, 0, 1])\n",
    "#         self.processed_input = tf.transpose(batch_input_)\n",
    "\n",
    "        VOCAB_LEN=19\n",
    "        EMBED_SIZE=50\n",
    "        embeddings =tf.Variable(tf.random_uniform([VOCAB_LEN, EMBED_SIZE]))\n",
    "#         word_embed = tf.placeholder(dtype=tf.int32, shape=(None,None), name='caption_p')\n",
    "        embed = tf.nn.embedding_lookup(embeddings, self.words)\n",
    "        self.processed_input = embed\n",
    "\n",
    "        self.initial_hidden = self.processed_input[:, 0, :]\n",
    "        self.initial_hidden = tf.matmul(self.initial_hidden, tf.zeros([input_nodes/2, hidden_unit]))\n",
    "#         self.initial_hidden = tf.zeros([None,hidden_unit])\n",
    "# \n",
    "    def Gru(self, previous_hidden_state, x):\n",
    "        x = K.expand_dims(x,0)\n",
    "        x = K.expand_dims(x,0)\n",
    "        features_try = K.tile(K.expand_dims(self.images, 1), [1, K.shape(x)[1], 1])\n",
    "        print(features_try.shape,x.shape)\n",
    "        embeddings = tf.concat([features_try,x],2)\n",
    "        print(\"embed ip:\",embeddings.shape)\n",
    "        \n",
    "        z = tf.sigmoid(tf.matmul(embeddings[0], self.Wz) + self.bz)\n",
    "        r = tf.sigmoid(tf.matmul(embeddings[0], self.Wr) + self.br)\n",
    "\n",
    "        h_ = tf.tanh(tf.matmul(embeddings[0], self.Wx) +\n",
    "                     tf.matmul(previous_hidden_state, self.Wh) * r)\n",
    "\n",
    "        current_hidden_state = tf.multiply( (1 - z), h_) + tf.multiply(previous_hidden_state, z)\n",
    "\n",
    "        return current_hidden_state\n",
    "\n",
    "    def get_states(self):\n",
    "#         all_hidden_states=[]\n",
    "#         prev_hidden_state = self.initial_hidden\n",
    "#         for inp in self.processed_input:\n",
    "#             features_try = K.tile(K.expand_dims(self.inputs, 1), [1, K.shape(embed)[1], 1])\n",
    "#             embeddings = tf.concat([features_try,embed],2)\n",
    "#             prev_hidden_state = self.Gru(prev_hidden_state,embeddings)\n",
    "#             all_hidden_states.append(prev_hidden_state)\n",
    "#         for i in range(len(self.processed_input)):\n",
    "        print(\"%%\",self.processed_input[0].shape,self.initial_hidden.shape)\n",
    "        x=self.processed_input[0]\n",
    "        all_hidden_states = tf.scan(self.Gru, x, initializer=self.initial_hidden, name='states')\n",
    "        print(\"all_ht:\",all_hidden_states.shape)\n",
    "        return all_hidden_states\n",
    "\n",
    "    def get_output(self, hidden_state):\n",
    "        output = tf.nn.relu(tf.matmul(hidden_state, self.Wo) + self.bo)\n",
    "        print(\"op:\",output.shape)\n",
    "        return output\n",
    "\n",
    "    def get_outputs(self):\n",
    "        all_hidden_states = self.get_states()\n",
    "        all_outputs = tf.map_fn(self.get_output, all_hidden_states)\n",
    "        print(\"all_op:\",all_outputs.shape)\n",
    "        return all_outputs\n",
    "    \n",
    "    def get_last_output(self):\n",
    "        all_ht = self.get_states()\n",
    "        last_ht = all_ht[-1]\n",
    "        return(self.get_output(last_ht))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm_wrapper(inputs, is_training, decay = 0.999):\n",
    "\n",
    "    scale = tf.Variable(tf.ones([inputs.get_shape()[-1]]))\n",
    "    beta = tf.Variable(tf.zeros([inputs.get_shape()[-1]]))\n",
    "    pop_mean = tf.Variable(tf.zeros([inputs.get_shape()[-1]]), trainable=False)\n",
    "    pop_var = tf.Variable(tf.ones([inputs.get_shape()[-1]]), trainable=False)\n",
    "\n",
    "    if is_training:\n",
    "        batch_mean, batch_var = tf.nn.moments(inputs,[0])\n",
    "        train_mean = tf.assign(pop_mean,\n",
    "                               pop_mean * decay + batch_mean * (1 - decay))\n",
    "        train_var = tf.assign(pop_var,\n",
    "                              pop_var * decay + batch_var * (1 - decay))\n",
    "        with tf.control_dependencies([train_mean, train_var]):\n",
    "            return tf.nn.batch_normalization(inputs,batch_mean, batch_var, beta, scale, epsilon)\n",
    "    else:\n",
    "        return tf.nn.batch_normalization(inputs,pop_mean, pop_var, beta, scale, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tf.placeholder(\"float\", [None,28,28,1])\n",
    "# y = tf.placeholder(\"float\", [None, n_classes])\n",
    "def cnn(x,weights,biases):\n",
    "    print(\"in cnn\")\n",
    "    \n",
    "    '''\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([3,3,1,32])),#56\n",
    "               'W_conv2':tf.Variable(tf.random_normal([3,3,32,32])),#56\n",
    "               'W_conv3':tf.Variable(tf.random_normal([3,3,32,64])),#28\n",
    "               'W_conv4':tf.Variable(tf.random_normal([3,3,64,64])),#28\n",
    "               'W_conv5':tf.Variable(tf.random_normal([3,3,64,128])),#14\n",
    "               'W_conv6':tf.Variable(tf.random_normal([3,3,128,128])),#14\n",
    "               'W_fc1':tf.Variable(tf.random_normal([7*7*128,1024])),  # since 3 times maxpooling.. inputsize/2^3\n",
    "               'W_fc2':tf.Variable(tf.random_normal([1024,1024]))\n",
    "              }\n",
    "                  # depending on what that repeat vector does\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "               'b_conv2':tf.Variable(tf.random_normal([32])),\n",
    "               'b_conv3':tf.Variable(tf.random_normal([64])),\n",
    "               'b_conv4':tf.Variable(tf.random_normal([64])),\n",
    "               'b_conv5':tf.Variable(tf.random_normal([128])),\n",
    "               'b_conv6':tf.Variable(tf.random_normal([128])),\n",
    "               'b_fc1':tf.Variable(tf.random_normal([1024])),\n",
    "               'b_fc2':tf.Variable(tf.random_normal([1024]))\n",
    "             }\n",
    "    '''\n",
    "    \n",
    "    print(\"-1\")\n",
    "#     x = tf.convert_to_tensor(x)\n",
    "    print(\"00\")\n",
    "    print(\"bef\",x.shape)\n",
    "    x = tf.reshape(x, shape=[-1, 224, 224, 3])\n",
    "    print(\"aft\",x.shape)\n",
    "    print(\"0\")\n",
    "    conv1 = tf.nn.relu(conv2d(x, weights['W_conv1'])+  biases['bc1'])\n",
    "    print(\"********\",weights['W_conv1'])\n",
    "    print(\"1\")\n",
    "    print(\"conv1:\",conv1.shape)\n",
    "    conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['bc2'])\n",
    "    print(\"2\")\n",
    "    print(\"conv2:\",conv2.shape)\n",
    "    conv2 = maxpool2d(conv2)\n",
    "    print(\"3\")\n",
    "    print(\"maxpool:\",conv2.shape)\n",
    "#     conv2 = tf.nn.dropout(conv2, 0.25)\n",
    "#     print(\"dropout:\",conv2.shape)\n",
    "    print(\"okay\")\n",
    "    \n",
    "    conv3 = tf.nn.relu(conv2d(conv2, weights['W_conv3']) + biases['bc3'])\n",
    "    print(\"conv3:\",conv3.shape)\n",
    "    conv4 = tf.nn.relu(conv2d(conv3, weights['W_conv4']) + biases['bc4'])\n",
    "    print(\"conv3:\",conv3.shape)\n",
    "    #conv4 = conv3\n",
    "    conv4 = maxpool2d(conv4)\n",
    "    print(\"maxpool:\",conv4.shape)\n",
    "#     conv4 = tf.nn.dropout(conv4, 0.25)\n",
    "    \n",
    "    conv5 = tf.nn.relu(conv2d(conv4, weights['W_conv5']) + biases['bc5'])\n",
    "    print(\"conv5:\",conv5.shape)\n",
    "    conv6 = tf.nn.relu(conv2d(conv5, weights['W_conv6']) + biases['bc6'])\n",
    "    print(\"conv6:\",conv6.shape)\n",
    "    #conv6 = conv5\n",
    "    conv6 = maxpool2d(conv6)\n",
    "    print(\"conv6:\",conv6.shape)\n",
    "#     conv6 = tf.nn.dropout(conv6, 0.25)\n",
    "\n",
    "    fc1 = tf.reshape(conv6,[-1, weights['W_fc1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.nn.relu(tf.matmul(fc1, weights['W_fc1'])+biases['b_fc1'])\n",
    "    print(\"fc1:\",fc1.shape)\n",
    "#     fc1 = tf.nn.dropout(fc1, 0.3)\n",
    "    \n",
    "    fc2 = tf.nn.relu(tf.matmul(fc1, weights['W_fc2'])+biases['b_fc2'])\n",
    "#     fc2 = tf.nn.dropout(fc2, 0.3)  \n",
    "    #fc2 = fc1\n",
    "    \n",
    "#     out = tf.add(tf.matmul(fc2, weights['out']), biases['out'])\n",
    "    print(\"fc2:\",fc2.shape)\n",
    "    print(fc2)\n",
    "    \n",
    "#     x_norm = batch_norm_wrapper(fc2,is_training)\n",
    "    \n",
    "    \n",
    "#     inputs=fc2\n",
    "#     scale = tf.Variable(tf.ones([inputs.get_shape()[-1]]))\n",
    "#     beta = tf.Variable(tf.zeros([inputs.get_shape()[-1]]))\n",
    "#     pop_mean = tf.Variable(tf.zeros([inputs.get_shape()[-1]]), trainable=False)\n",
    "#     pop_var = tf.Variable(tf.ones([inputs.get_shape()[-1]]), trainable=False)\n",
    "#     decay=0.9999\n",
    "\n",
    "#     if is_training:\n",
    "#         batch_mean, batch_var = tf.nn.moments(inputs,[0])\n",
    "#         train_mean = tf.assign(pop_mean,\n",
    "#                                pop_mean * decay + batch_mean * (1 - decay))\n",
    "#         train_var = tf.assign(pop_var,\n",
    "#                               pop_var * decay + batch_var * (1 - decay))\n",
    "#         with tf.control_dependencies([train_mean, train_var]):\n",
    "#             return tf.nn.batch_normalization(inputs,batch_mean, batch_var, beta, scale, epsilon)\n",
    "#     else:\n",
    "#         return tf.nn.batch_normalization(inputs,pop_mean, pop_var, beta, scale, epsilon)\n",
    "    \n",
    "    \n",
    "#     x_norm = tf.layers.batch_normalization(fc2, training=True)\n",
    "#     input_gru = tf.repeat(fc2,)\n",
    "    \n",
    "#     print(x_norm.shape)\n",
    "    return fc2\n",
    "\n",
    "# def Gru(hidden_size):  \n",
    "#     gru = GRU(1024,hidden_size)\n",
    "\n",
    "#     W_output = tf.Variable(tf.truncated_normal(dtype=tf.float64, shape=(hidden_size, 1), mean=0, stddev=0.01))\n",
    "#     b_output = tf.Variable(tf.truncated_normal(dtype=tf.float64, shape=(1,), mean=0, stddev=0.01))\n",
    "#     output = tf.map_fn(lambda h_t: tf.matmul(h_t, W_output) + b_output, gru.h_t)\n",
    "\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.utils.data as data\n",
    "import cv2\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def resize_img(png_file_path):\n",
    "        img_rgb = cv2.imread(png_file_path)\n",
    "        img_grey = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "        img_adapted = cv2.adaptiveThreshold(img_grey, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY, 101, 9)\n",
    "        img_stacked = np.repeat(img_adapted[...,None],3,axis=2)\n",
    "        resized = cv2.resize(img_stacked, (224,224), interpolation=cv2.INTER_AREA)\n",
    "        bg_img = 255 * np.ones(shape=(224,224,3))\n",
    "#         print(bg_img.shape,resized.shape)\n",
    "        bg_img[0:224, 0:224,:] = resized\n",
    "        bg_img /= 255\n",
    "        bg_img = np.rollaxis(bg_img, 2, 0)  \n",
    "#         print(bg_img.shape)\n",
    "        return bg_img\n",
    "    \n",
    "def load_doc(filename):\n",
    "    file = open(filename, 'r',encoding='UTF-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, data_dir, input_transform=None, target_transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_filenames = []\n",
    "        self.texts = []\n",
    "        all_filenames = listdir(data_dir)\n",
    "        all_filenames.sort()\n",
    "        for filename in (all_filenames):\n",
    "            if filename[-3:] == \"png\":\n",
    "                self.image_filenames.append(filename)\n",
    "            else:\n",
    "                text = '<START> ' + load_doc(self.data_dir+filename) + ' <END>'\n",
    "                text = ' '.join(text.split())\n",
    "                text = text.replace(',', ' ,')\n",
    "                self.texts.append(text)\n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        # Initialize the function to create the vocabulary \n",
    "        tokenizer = Tokenizer(filters='', split=\" \", lower=False)\n",
    "        # Create the vocabulary \n",
    "        tokenizer.fit_on_texts([load_doc('vocabulary.vocab')])\n",
    "        self.tokenizer = tokenizer\n",
    "        # Add one spot for the empty word in the vocabulary \n",
    "        self.vocab_size = len(tokenizer.word_index) + 1\n",
    "        # Map the input sentences into the vocabulary indexes\n",
    "        self.train_sequences = tokenizer.texts_to_sequences(self.texts)\n",
    "        # The longest set of boostrap tokens\n",
    "        self.max_sequence = max(len(s) for s in self.train_sequences)\n",
    "        # Specify how many tokens to have in each input sentence\n",
    "        self.max_length = 48\n",
    "        \n",
    "        X, y, image_data_filenames = list(), list(), list()\n",
    "        for img_no, seq in enumerate(self.train_sequences):\n",
    "            in_seq, out_seq = seq[:-1], seq[1:]\n",
    "            out_seq = to_categorical(out_seq, num_classes=self.vocab_size)\n",
    "            image_data_filenames.append(self.image_filenames[img_no])\n",
    "            X.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "                \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.image_data_filenames = image_data_filenames\n",
    "        self.images = list()\n",
    "        for image_name in self.image_data_filenames:\n",
    "            image = resize_img(self.data_dir+image_name)\n",
    "            self.images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'all_data5/'\n",
    "batch_size = 32\n",
    "my_dateset = Dataset(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(my_dateset.images,dtype=np.float32)\n",
    "for i in range(len(x_train)):\n",
    "    x_train[i]=np.array(x_train[i],dtype=np.float32)\n",
    "print(x_train.shape)\n",
    "# batch_size = 128\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((x))\n",
    "# iterator = dataset.repeat().batch(batch_size).make_initializable_iterator()\n",
    "# data_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in cnn\n",
      "-1\n",
      "00\n",
      "bef (?, 3, 224, 224)\n",
      "aft (?, 224, 224, 3)\n",
      "0\n",
      "******** <tf.Variable 'W0:0' shape=(3, 3, 3, 32) dtype=float32_ref>\n",
      "1\n",
      "conv1: (?, 224, 224, 32)\n",
      "2\n",
      "conv2: (?, 224, 224, 32)\n",
      "3\n",
      "maxpool: (?, 112, 112, 32)\n",
      "okay\n",
      "conv3: (?, 112, 112, 64)\n",
      "conv3: (?, 112, 112, 64)\n",
      "maxpool: (?, 56, 56, 64)\n",
      "conv5: (?, 56, 56, 128)\n",
      "conv6: (?, 56, 56, 128)\n",
      "conv6: (?, 28, 28, 128)\n",
      "fc1: (?, 1024)\n",
      "fc2: (?, 50)\n",
      "Tensor(\"Relu_7:0\", shape=(?, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "im = tf.placeholder(dtype=tf.float32, shape=(None,3,224,224), name='im')\n",
    "# is_training = tf.placeholder(dtype=tf.bool, name=\"is_training\")\n",
    "model1 = cnn(im,weights,biases)\n",
    "output_train = batch_norm_wrapper(model1,True)\n",
    "output_test = batch_norm_wrapper(model1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 50)\n",
      "%% (?, 50) (?, 256)\n",
      "(?, 1, 50) (1, 1, 50)\n",
      "embed ip: (1, 1, 100)\n",
      "all_ht: (?, ?, 256)\n",
      "op: (?, 18)\n",
      "all_op: (?, ?, 18)\n",
      "full: (?, ?, 18)\n",
      "%% (?, 50) (?, 256)\n",
      "(?, 1, 50) (1, 1, 50)\n",
      "embed ip: (1, 1, 100)\n",
      "all_ht: (?, ?, 256)\n",
      "op: (?, 18)\n",
      "ol: (?, 18)\n"
     ]
    }
   ],
   "source": [
    "gru = GRU_cell(100,256,18)\n",
    "hidden_size=256\n",
    "\n",
    "# W_output = tf.Variable(tf.truncated_normal(dtype=tf.float64, shape=(hidden_size, 18), mean=0, stddev=0.01),trainable=True)\n",
    "# b_output = tf.Variable(tf.truncated_normal(dtype=tf.float64, shape=(18,), mean=0, stddev=0.01),trainable=True)\n",
    "\n",
    "# W_output = weights['out']\n",
    "# b_output = biases['out']\n",
    "\n",
    "# output = tf.map_fn(lambda h_t: tf.matmul(h_t, W_output) + b_output, gru.h_t)\n",
    "\n",
    "# output1 = tf.nn.relu(tf.matmul(gru.h_t,W_output)+b_output)\n",
    "# out2 = tf.matmul(gru.h_t[0], W_output)+b_output\n",
    "\n",
    "# tf.get_variable('W7', shape=(1024,50), initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "# out3 = gru.h_t\n",
    "# outs = gru.outputs\n",
    "print(gru.processed_input.shape)\n",
    "# print(gru.images.shape)\n",
    "\n",
    "\n",
    "output = gru.get_outputs()\n",
    "# hidden = gru.get_states()\n",
    "# print(output.shape)\n",
    "print(\"full:\",output.shape)\n",
    "ol = gru.get_last_output()\n",
    "print(\"ol:\",ol.shape)\n",
    "# print(hidden.shape)\n",
    "# print(gru.h_t.shape)\n",
    "# print(out3.shape)\n",
    "# print(gru.outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(59,)\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "y_train = my_dateset.X\n",
    "y_train=np.array(y_train)\n",
    "        \n",
    "for i in range(len(y_train)):\n",
    "    y_train[i]=np.array(y_train[i])\n",
    "#     for j in range(len(x1[i])):\n",
    "#         x1[i][j]=np.array(x1[i][j])\n",
    "print(y_train.shape)\n",
    "print(y_train[0].shape)\n",
    "    \n",
    "\n",
    "# x1=tf.constant(x1[0])\n",
    "print(\"hi\")\n",
    "            \n",
    "VOCAB_LEN=19\n",
    "EMBED_SIZE=50\n",
    "embeddings = tf.Variable(tf.random_uniform([VOCAB_LEN, EMBED_SIZE]))\n",
    "caption_p = tf.placeholder(dtype=tf.int32, shape=(None,None), name='caption_p')\n",
    "embed = tf.nn.embedding_lookup(embeddings, caption_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "expected = my_dateset.y\n",
    "expected=np.array(expected)\n",
    "for e in range(len(expected)):\n",
    "    expected[e]=np.array(expected[e])\n",
    "print(expected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_output = tf.placeholder(dtype=tf.float32, shape=(None,None,None), name='expected_output')\n",
    "loss = tf.reduce_sum(tf.squared_difference(ol ,expected_output)) #/ float(1)\n",
    "# e_loss = tf.placeholder(dtype=tf.float64,name='e_loss')\n",
    "# epoch_loss = tf.reduce_sum(e_loss)\n",
    "# train2 = tf.train.AdamOptimizer(0.0001).minimize(tf.reduce_sum(e_loss))\n",
    "# train_step = tf.train.AdamOptimizer().minimize()\n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools \n",
    "def pad(batch_y):\n",
    "    print(batch_y.shape)\n",
    "    x=0\n",
    "    for y in batch_y:\n",
    "        if(len(y)>x):\n",
    "            x=len(y)\n",
    "#     x = functools.reduce(lambda x,y: len(x) if(len(x)>len(y)) else len(y),batch_y)\n",
    "    \n",
    "    ret = []\n",
    "    for y in range(len(batch_y)):\n",
    "        res=np.zeros(x)\n",
    "        s = batch_y[y]\n",
    "        res[0:len(s)]=batch_y[y]\n",
    "#         batch_y[y]=res\n",
    "        ret.append(res)\n",
    "    return np.array(ret)\n",
    "        \n",
    "        \n",
    "# a=[[1,2],[1,2,3]]\n",
    "# pad(a)\n",
    "\n",
    "def pad2(batch_ex):\n",
    "#     r = functools.reduce(lambda x,y: len(x) if(len(x)>len(y)) else len(y),batch_ex)\n",
    "#     print(\":::::\",r)\n",
    "    r=0\n",
    "    c=0\n",
    "    for ex in batch_ex:\n",
    "        shape = ex.shape\n",
    "#         print(shape)\n",
    "        if(shape[0]>r):\n",
    "            r=shape[0]\n",
    "        if(shape[1]>c):\n",
    "            c=shape[1]\n",
    "#     c = functools.reduce(lambda x,y: len(x[0]) if(len(x[0])>len(y[0])) else len(y[0]),batch_ex)\n",
    "#     print(\":::::\",c)\n",
    "#     print(r,c)\n",
    "    ret=[]\n",
    "    for ex in batch_ex:\n",
    "        res=np.zeros((r,c))\n",
    "#         print(res.shape)\n",
    "#         print(ex.shape)\n",
    "        res[0:ex.shape[0],0:ex.shape[1]]=ex\n",
    "        ret.append(res)\n",
    "#     print(ret)\n",
    "        \n",
    "    return(np.array(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "batch  0\n",
      "x: 1\n",
      "y: 1\n",
      "ex: 1\n",
      "bex: (1, 59, 18)\n",
      "(1, 59)\n",
      "c: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "emb: (10, 94, 100)\n",
      "a: (1, 18) \n",
      "\n",
      "1006.5386352539062\n",
      "\n",
      "\n",
      "\n",
      "batch  1\n",
      "x: 1\n",
      "y: 1\n",
      "ex: 1\n",
      "bex: (1, 94, 18)\n",
      "(1, 94)\n",
      "c: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "emb: (10, 94, 100)\n",
      "a: (1, 18) \n",
      "\n",
      "1598.0025634765625\n",
      "\n",
      "\n",
      "\n",
      "batch  2\n",
      "x: 1\n",
      "y: 1\n",
      "ex: 1\n",
      "bex: (1, 76, 18)\n",
      "(1, 76)\n",
      "c: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "emb: (10, 94, 100)\n",
      "a: (1, 18) \n",
      "\n",
      "1291.0029296875\n",
      "\n",
      "\n",
      "\n",
      "batch  3\n",
      "x: 1\n",
      "y: 1\n",
      "ex: 1\n",
      "bex: (1, 26, 18)\n",
      "(1, 26)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-f9bc7dc9c9be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#             print(batch_ex.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;31m# image = K.expand_dims(x[i], 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# print(\"im:\",image.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 5\n",
    "vocab_size = 19\n",
    "batch_size=1\n",
    "\n",
    "x_train = my_dateset.images\n",
    "caption = my_dateset.X\n",
    "expected = my_dateset.y\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    loss_ar=[]\n",
    "    for e in range(epoch):\n",
    "        loss_no=[]\n",
    "        print(e)\n",
    "        for batch in range(len(x_train)//batch_size):\n",
    "            print(\"batch \",batch)\n",
    "            batch_x = x_train[batch*batch_size:min((batch+1)*batch_size,len(x_train))]\n",
    "            batch_y = caption[batch*batch_size:min((batch+1)*batch_size,len(caption))] \n",
    "            batch_ex = expected[batch*batch_size:min((batch+1)*batch_size,len(expected))]\n",
    "            print(\"x:\",len(batch_x))\n",
    "            print(\"y:\",len(batch_y))\n",
    "            print(\"ex:\",len(batch_ex))\n",
    "            \n",
    "#             print(batch_y)\n",
    "            \n",
    "            batch_x = np.array(batch_x)\n",
    "            for b in range(len(batch_x)):\n",
    "                batch_x[b]=np.array(batch_x[b])\n",
    "            batch_y = np.array(batch_y)\n",
    "            for b in range(len(batch_y)):\n",
    "                batch_y[b]=np.array(batch_y[b])\n",
    "            batch_ex = np.array(batch_ex)\n",
    "            for b in range(len(batch_ex)):\n",
    "                batch_ex[b]=np.array(batch_ex[b])\n",
    "                \n",
    "            print(\"bex:\",batch_ex.shape)\n",
    "#             print(batch_ex[0].shape)\n",
    "                \n",
    "            batch_y = pad(batch_y)\n",
    "            batch_ex = pad2(batch_ex)\n",
    "            \n",
    "#             batch_y = batch_y.reshape((-1,1))\n",
    "#             print(batch_ex.shape)\n",
    "            \n",
    "            sess.run(init)\n",
    "            # image = K.expand_dims(x[i], 0)\n",
    "            # print(\"im:\",image.shape)\n",
    "            c,m = sess.run([output_train,model1],feed_dict={im:batch_x})\n",
    "            print(\"c:\",c)\n",
    "            \n",
    "#             x_norm = batch_norm_wrapper(c,True,)\n",
    "            \n",
    "#             x_norm = tf.layers.batch_normalization(c, training=True)\n",
    "#             x = sess.run(x_norm)\n",
    "#             print(x.shape)\n",
    "#             # em = K.expand_dims(x1[i], 0)\n",
    "\n",
    "#             inp2 = sess.run(embed,feed_dict={caption_p:batch_y})\n",
    "#             print(\"inp2:\",inp2.shape)\n",
    "\n",
    "#             features_try = K.tile(K.expand_dims(c, 1), [1, K.shape(inp2)[1], 1])\n",
    "#             print(\"ktile:\",features_try.shape)\n",
    "            embeddings = tf.concat([features_try,inp2],2)\n",
    "            print(\"emb:\",embeddings.shape)\n",
    "            inp = sess.run(embeddings)\n",
    "\n",
    "            a = sess.run(ol,feed_dict={gru.images:c,gru.words:batch_y})\n",
    "            print(\"a:\",a.shape,\"\\n\")\n",
    "\n",
    "            # print(\"Sssss:\",ex.shape)\n",
    "            ls,tr = sess.run([loss,train_step],feed_dict ={expected_output:batch_ex,gru.images:c,gru.words:batch_y})\n",
    "            print(ls/batch_size)\n",
    "            loss_no.append(ls/batch_size)\n",
    "            print(\"\\n\\n\")\n",
    "#         el = sess.run(epoch_loss,feed_dict={e_loss:loss_no})\n",
    "        loss_ar.append(loss_no)\n",
    "\n",
    "        print(\"-----------------------------------------------------------------\") \n",
    "    save_path = saver.save(sess, \"model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82.2716421177868, 92.81862903434791, 96.30940812570955, 84.75820456588983, 86.95217646124553, 78.29988489684754, 102.29989123686144, 98.14264792282572, 89.81742759596796, 110.03864119264809], [119.272947928158, 97.48594405296787, 107.28251140724505, 106.16270920030271, 109.26193702470599, 103.9932880860052, 83.27586920555275, 65.61239812023724, 103.1262389559671, 100.50055311180877], [107.35299611391278, 94.20644692274458, 92.5262013955177, 98.51224381989267, 84.46880247133484, 97.11596637441814, 86.22528406998772, 73.61804806208723, 89.15349053332109, 123.26068964406713], [99.53647862179639, 91.7311697680406, 84.16802474789583, 107.03807201975133, 66.93254981303151, 78.67394327839861, 102.06400343448196, 96.05603672002141, 95.07008435066464, 99.2345743383708], [105.76051951369845, 99.5854322749878, 84.15821082562589, 92.1515492042857, 89.92220258869473, 83.75604667947928, 99.69011185893811, 83.38375060660101, 89.92259518919097, 87.8045557599808]]\n"
     ]
    }
   ],
   "source": [
    "print(loss_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "def load_val_images(data_dir):\n",
    "    image_filenames =[]\n",
    "    images = []\n",
    "    all_filenames = listdir(data_dir)\n",
    "    all_filenames.sort()\n",
    "    for filename in (all_filenames):\n",
    "        if filename[-3:] == \"png\":\n",
    "            image_filenames.append(filename)\n",
    "    for name in image_filenames:\n",
    "        image = resize_img(data_dir+name)\n",
    "        images.append(image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_words = []\n",
    "star_text = '<START> '\n",
    "image = load_val_images('all_data6/')[0]\n",
    "img_tensor=np.expand_dims(np.array(image),0)\n",
    "img_tensor=np.array(img_tensor)\n",
    "''''image = Variable(torch.FloatTensor([image]))'''\n",
    "predicted = '<START> '\n",
    " \n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model.ckpt\n",
      "<START>text \n",
      "<START>text text \n",
      "<START>text text text \n",
      "<START>text text text text \n",
      "<START>text text text text text \n",
      "<START>text text text text text text \n",
      "<START>text text text text text text text \n",
      "<START>text text text text text text text text \n",
      "<START>text text text text text text text text text \n",
      "<START>text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n",
      "<START>text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text \n"
     ]
    }
   ],
   "source": [
    "predicted='<START>'\n",
    "with tf.Session() as sess:\n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess.run(init)\n",
    "    saver.restore(sess, \"model.ckpt\")\n",
    "#     print(\"####\",weights['W_conv1'].eval())\n",
    "    for di in range(50):\n",
    "        sequence = my_dateset.tokenizer.texts_to_sequences([star_text])[0]\n",
    "#         print(sequence)\n",
    "        decoder_input = np.array(sequence).reshape(-1,1)\n",
    "#         c = sess.run(model1,feed_dict={im:img_tensor})\n",
    "#         print(\"--------------------------\")\n",
    "        c,m = sess.run([output_test,model1],feed_dict={im:img_tensor})\n",
    "#         print(di, c)\n",
    "#         print(\"--------------------------\")\n",
    "        \n",
    "        inp2 = sess.run(embed,feed_dict={caption_p:decoder_input})\n",
    "        print(inp2)\n",
    "        features_try = K.tile(K.expand_dims(c, 1), [1, K.shape(inp2)[1], 1])\n",
    "        embeddings = tf.concat([features_try,inp2],2)\n",
    "        inp = sess.run(embeddings)\n",
    "        a = sess.run(output1,feed_dict={gru.input_layer:inp})\n",
    "        data=list(a[0][0])\n",
    "        i=data.index(max(data))\n",
    "        word = word_for_id(i,my_dateset.tokenizer)\n",
    "        if word is None:\n",
    "            continue\n",
    "        predicted += word + ' '\n",
    "        star_text = word\n",
    "        print(predicted)\n",
    "        if word == '<END>':\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
